{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-26T14:40:15.320131Z",
     "iopub.status.busy": "2023-09-26T14:40:15.319872Z",
     "iopub.status.idle": "2023-09-26T14:40:20.953313Z",
     "shell.execute_reply": "2023-09-26T14:40:20.952266Z",
     "shell.execute_reply.started": "2023-09-26T14:40:15.320106Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import timeit\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-26T14:40:20.963686Z",
     "iopub.status.busy": "2023-09-26T14:40:20.958652Z",
     "iopub.status.idle": "2023-09-26T14:40:21.008339Z",
     "shell.execute_reply": "2023-09-26T14:40:21.007489Z",
     "shell.execute_reply.started": "2023-09-26T14:40:20.963650Z"
    }
   },
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42\n",
    "BATCH_SIZE = 512\n",
    "EPOCHS = 40\n",
    "LEARNING_RATE = 1e-4\n",
    "NUM_CLASSES = 10\n",
    "PATCH_SIZE = 4\n",
    "IMG_SIZE = 28\n",
    "IN_CHANNELS = 1\n",
    "NUM_HEADS = 8\n",
    "DROPOUT = 0.001\n",
    "HIDDEN_DIM = 768\n",
    "ADAM_WEIGHT_DECAY = 0\n",
    "ADAM_BETAS = (0.9, 0.999)\n",
    "ACTIVATION=\"gelu\"\n",
    "NUM_ENCODERS = 4\n",
    "EMBED_DIM = (PATCH_SIZE ** 2) * IN_CHANNELS # 16\n",
    "NUM_PATCHES = (IMG_SIZE // PATCH_SIZE) ** 2 # 49\n",
    "\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "torch.cuda.manual_seed(RANDOM_SEED)\n",
    "torch.cuda.manual_seed_all(RANDOM_SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-26T14:44:18.472373Z",
     "iopub.status.busy": "2023-09-26T14:44:18.471676Z",
     "iopub.status.idle": "2023-09-26T14:44:23.087786Z",
     "shell.execute_reply": "2023-09-26T14:44:23.086684Z",
     "shell.execute_reply.started": "2023-09-26T14:44:18.472339Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 50, 16])\n"
     ]
    }
   ],
   "source": [
    "class PatchEmbedding(nn.Module):\n",
    "    def __init__(self, embed_dim, patch_size, num_patches, dropout, in_channels):\n",
    "        super().__init__()\n",
    "        self.patcher = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=in_channels,\n",
    "                out_channels=embed_dim,\n",
    "                kernel_size=patch_size,\n",
    "                stride=patch_size,\n",
    "            ),                  \n",
    "            nn.Flatten(2))\n",
    "\n",
    "        self.cls_token = nn.Parameter(torch.randn(size=(1, in_channels, embed_dim)), requires_grad=True)\n",
    "        self.position_embeddings = nn.Parameter(torch.randn(size=(1, num_patches+1, embed_dim)), requires_grad=True)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        cls_token = self.cls_token.expand(x.shape[0], -1, -1)\n",
    "\n",
    "        x = self.patcher(x).permute(0, 2, 1)\n",
    "        x = torch.cat([cls_token, x], dim=1)\n",
    "        x = self.position_embeddings + x \n",
    "        x = self.dropout(x)\n",
    "        return x\n",
    "    \n",
    "model = PatchEmbedding(EMBED_DIM, PATCH_SIZE, NUM_PATCHES, DROPOUT, IN_CHANNELS).to(device)\n",
    "x = torch.randn(512, 1, 28, 28).to(device)\n",
    "print(model(x).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-26T14:44:34.029391Z",
     "iopub.status.busy": "2023-09-26T14:44:34.029018Z",
     "iopub.status.idle": "2023-09-26T14:44:34.122786Z",
     "shell.execute_reply": "2023-09-26T14:44:34.121796Z",
     "shell.execute_reply.started": "2023-09-26T14:44:34.029359Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arkadiy-a/ml-platform/vit-exp/vit-exp/lib/python3.11/site-packages/torch/nn/modules/transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 10])\n"
     ]
    }
   ],
   "source": [
    "class ViT(nn.Module):\n",
    "    def __init__(self, num_patches, img_size, num_classes, patch_size, embed_dim, num_encoders, num_heads, hidden_dim, dropout, activation, in_channels):\n",
    "        super().__init__()\n",
    "        self.embeddings_block = PatchEmbedding(embed_dim, patch_size, num_patches, dropout, in_channels)\n",
    "        \n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=embed_dim, nhead=num_heads, dropout=dropout, activation=activation, batch_first=True, norm_first=True)\n",
    "        self.encoder_blocks = nn.TransformerEncoder(encoder_layer, num_layers=num_encoders)\n",
    "\n",
    "        self.mlp_head = nn.Sequential(\n",
    "            nn.LayerNorm(normalized_shape=embed_dim),\n",
    "            nn.Linear(in_features=embed_dim, out_features=num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embeddings_block(x)\n",
    "        x = self.encoder_blocks(x)\n",
    "        x = self.mlp_head(x[:, 0, :])  # Apply MLP on the CLS token only\n",
    "        return x\n",
    "\n",
    "model = ViT(NUM_PATCHES, IMG_SIZE, NUM_CLASSES, PATCH_SIZE, EMBED_DIM, NUM_ENCODERS, NUM_HEADS, HIDDEN_DIM, DROPOUT, ACTIVATION, IN_CHANNELS).to(device)\n",
    "x = torch.randn(512, 1, 28, 28).to(device)\n",
    "print(model(x).shape) # BATCH_SIZE X NUM_CLASSES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-26T14:44:35.975856Z",
     "iopub.status.busy": "2023-09-26T14:44:35.974369Z",
     "iopub.status.idle": "2023-09-26T14:44:41.635006Z",
     "shell.execute_reply": "2023-09-26T14:44:41.634012Z",
     "shell.execute_reply.started": "2023-09-26T14:44:35.975813Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"digit-recognizer/train.csv\")\n",
    "test_df = pd.read_csv(\"digit-recognizer/test.csv\")\n",
    "submission_df = pd.read_csv(\"digit-recognizer/sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-26T14:44:41.637438Z",
     "iopub.status.busy": "2023-09-26T14:44:41.637083Z",
     "iopub.status.idle": "2023-09-26T14:44:41.666402Z",
     "shell.execute_reply": "2023-09-26T14:44:41.665539Z",
     "shell.execute_reply.started": "2023-09-26T14:44:41.637406Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "2      1       0       0       0       0       0       0       0       0   \n",
       "3      4       0       0       0       0       0       0       0       0   \n",
       "4      0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0         0         0         0   \n",
       "3       0  ...         0         0         0         0         0         0   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-26T14:44:41.668330Z",
     "iopub.status.busy": "2023-09-26T14:44:41.667773Z",
     "iopub.status.idle": "2023-09-26T14:44:41.688494Z",
     "shell.execute_reply": "2023-09-26T14:44:41.687400Z",
     "shell.execute_reply.started": "2023-09-26T14:44:41.668298Z"
    }
   },
   "outputs": [],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-26T14:44:41.691818Z",
     "iopub.status.busy": "2023-09-26T14:44:41.691457Z",
     "iopub.status.idle": "2023-09-26T14:44:41.700019Z",
     "shell.execute_reply": "2023-09-26T14:44:41.698824Z",
     "shell.execute_reply.started": "2023-09-26T14:44:41.691782Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ImageId  Label\n",
       "0        1      0\n",
       "1        2      0\n",
       "2        3      0\n",
       "3        4      0\n",
       "4        5      0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-26T14:44:41.702090Z",
     "iopub.status.busy": "2023-09-26T14:44:41.701719Z",
     "iopub.status.idle": "2023-09-26T14:44:41.905219Z",
     "shell.execute_reply": "2023-09-26T14:44:41.904203Z",
     "shell.execute_reply.started": "2023-09-26T14:44:41.702017Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df, val_df = train_test_split(train_df, test_size=0.1, random_state=RANDOM_SEED, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-26T14:44:41.907233Z",
     "iopub.status.busy": "2023-09-26T14:44:41.906834Z",
     "iopub.status.idle": "2023-09-26T14:44:41.922234Z",
     "shell.execute_reply": "2023-09-26T14:44:41.921270Z",
     "shell.execute_reply.started": "2023-09-26T14:44:41.907200Z"
    }
   },
   "outputs": [],
   "source": [
    "class MNISTTrainDataset(Dataset):\n",
    "    def __init__(self, images, labels, indicies):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.indicies = indicies\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.ToPILImage(),\n",
    "            transforms.RandomRotation(15),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.5], [0.5])\n",
    "        ])\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx].reshape((28, 28)).astype(np.uint8)\n",
    "        label = self.labels[idx]\n",
    "        index = self.indicies[idx]\n",
    "        image = self.transform(image)\n",
    "        \n",
    "        return {\"image\": image, \"label\": label, \"index\": index}\n",
    "    \n",
    "class MNISTValDataset(Dataset):\n",
    "    def __init__(self, images, labels, indicies):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.indicies = indicies\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.5], [0.5])\n",
    "        ])\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx].reshape((28, 28)).astype(np.uint8)\n",
    "        label = self.labels[idx]\n",
    "        index = self.indicies[idx]\n",
    "        image = self.transform(image)\n",
    "        \n",
    "        return {\"image\": image, \"label\": label, \"index\": index}\n",
    "    \n",
    "class MNISTSubmitDataset(Dataset):\n",
    "    def __init__(self, images, indicies):\n",
    "        self.images = images\n",
    "        self.indicies = indicies\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.5], [0.5])\n",
    "        ])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx].reshape((28, 28)).astype(np.uint8)\n",
    "        index = self.indicies[idx]\n",
    "        image = self.transform(image)\n",
    "        \n",
    "        return {\"image\": image, \"index\": index}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-26T14:44:41.924318Z",
     "iopub.status.busy": "2023-09-26T14:44:41.923825Z",
     "iopub.status.idle": "2023-09-26T14:44:42.501398Z",
     "shell.execute_reply": "2023-09-26T14:44:42.500478Z",
     "shell.execute_reply.started": "2023-09-26T14:44:41.924281Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37800\n",
      "{'image': tensor([[[-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -0.9373, -0.3804,  0.2314,  0.9922,  0.3020,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -0.0902,  0.5843,  0.9843,  0.9843,  0.9843,  0.9843, -0.7176,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.1137,\n",
      "           0.9608,  0.9922,  0.9843,  0.9843,  0.9451,  0.8902, -0.5843,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.6784,  0.7725,\n",
      "           0.9843,  0.9137, -0.1294, -0.3412, -0.5059, -0.7176, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  0.3412,  0.9843,\n",
      "           0.6392, -0.7255, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  0.8353,  0.5608,\n",
      "          -0.8588, -1.0000, -1.0000, -1.0000, -1.0000,  0.3176,  0.3176,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -0.4902,  0.8902, -0.5608,\n",
      "          -1.0000, -1.0000, -1.0000, -0.9373,  0.2235,  0.6314, -0.2392,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000,  0.4275,  0.8196, -0.8824,\n",
      "          -0.8275, -0.8275, -0.5529,  0.7647,  0.8902, -0.2863, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -0.9137,  0.6157,  0.8667,  0.4980,\n",
      "           0.9843,  1.0000,  0.9843,  0.0510, -0.7176, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -0.9451,  0.5765,  0.9843,  0.9843,\n",
      "           0.9843,  0.5059, -0.1843, -0.9059, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -0.6627,  0.9922,  0.9922,  0.9922,\n",
      "           0.0196, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -0.7176,  0.2392,  0.9843,  0.9843,  0.2627,\n",
      "          -0.9137, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -0.0902,  0.9686, -0.0745,  0.7020,  0.9451,\n",
      "          -0.2784, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000,  0.6627,  0.4510, -1.0000, -0.8745,  0.8196,\n",
      "           0.3647, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000,  0.6627, -0.1608, -1.0000, -1.0000, -0.0118,\n",
      "           0.9843, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -0.4902,  0.9922, -0.8588, -1.0000, -1.0000, -1.0000,\n",
      "           0.6706,  0.3176, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -0.6627,  0.8824,  0.1059, -1.0000, -1.0000, -1.0000,\n",
      "           0.0353,  0.6627, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000,  0.2471,  0.9686, -0.0667, -0.8431, -0.8824, -0.0667,\n",
      "           0.8039,  0.8039, -0.7882, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -0.3725,  0.7882,  0.9843,  0.9294,  0.7725,  0.9843,\n",
      "           0.6627, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -0.6627,  0.1529,  0.2235,  0.9843,  0.2941,\n",
      "          -0.3725, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000]]]), 'label': np.int64(8), 'index': np.int64(22460)}\n",
      "------------------------------\n",
      "4200\n",
      "{'image': tensor([[[-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9765,\n",
      "          -0.5137,  0.4510,  1.0000,  0.7961, -0.7804, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  0.3569,\n",
      "           0.9843,  0.9843,  0.9843,  0.9843, -0.3647, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -0.9843, -0.0118,  0.9686,\n",
      "           0.3961, -0.5686, -0.6000,  0.9843,  0.2235, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -0.4667,  0.9843,  0.2078,\n",
      "          -1.0000, -1.0000, -0.8980,  0.7020,  0.2235, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -0.9294,  0.7961,  0.4745, -0.9529,\n",
      "          -1.0000, -1.0000, -0.8275,  0.9843,  0.2235, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -0.9137,  0.9843,  0.3098, -1.0000,\n",
      "          -1.0000, -1.0000, -0.8275,  0.9843,  0.2549, -0.9137, -0.9294,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -0.9294,  0.8431,  0.3098, -1.0000,\n",
      "          -1.0000, -1.0000, -0.8275,  0.9843,  0.9843,  0.9843,  0.4745,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000,  0.2314,  0.8275, -0.8745,\n",
      "          -1.0000, -1.0000, -0.5373,  0.9843,  0.9843,  0.9137, -0.3882,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -0.1765,  0.9843, -0.8353,\n",
      "          -1.0000, -0.9529,  0.4431,  0.9843,  0.9373, -0.4196, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -0.6157,  0.9843, -0.1059,\n",
      "          -1.0000, -0.0902,  0.9843,  0.9843, -0.3176, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -0.9137,  0.3176,  0.9608,\n",
      "           0.5686,  0.8980,  0.9294,  0.0667, -0.9216, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.3176,  0.9843,\n",
      "           0.9843,  0.9843,  0.7412, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -0.7412,  0.5451,  0.9843,\n",
      "           0.9843,  0.9843, -0.2235, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -0.6392,  0.3647,  0.9843,  0.9843,\n",
      "           0.9843,  0.4039, -0.9765, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -0.6549,  0.8588,  0.9843,  0.8275,  0.0039,\n",
      "           0.6078,  0.2627, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000,  0.2157,  0.9843,  0.7255, -0.8510, -1.0000,\n",
      "           0.2706,  0.4510, -0.9686, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000,  0.4824,  0.9843,  0.7569, -0.4667, -1.0000,\n",
      "          -0.4275,  0.9843, -0.5294, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000,  0.2941,  0.8510,  0.9843,  0.9765,  0.8980,\n",
      "           0.6549,  0.9843, -0.0275, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -0.7176,  0.1137,  0.6235,  0.9843,\n",
      "           0.9843,  0.9843, -0.0275, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.8980,  0.0667,\n",
      "           0.6784,  0.3176, -0.8039, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000]]]), 'label': np.int64(8), 'index': np.int64(5457)}\n",
      "------------------------------\n",
      "28000\n",
      "{'image': tensor([[[-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -0.9216, -0.8667, -0.8667, -0.8667,\n",
      "          -0.8667, -0.3647,  0.4118,  0.4118, -0.7255, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000,  0.0902,  0.9843,  0.9843,  0.9843,\n",
      "           0.9843,  0.9843,  0.9843,  0.9843, -0.6235, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -0.5294,  0.7882,  0.9843,  0.9843,  0.9843,\n",
      "           0.9843,  0.9843,  0.9843,  0.9843,  0.6235,  0.5451, -0.6392,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000,  0.6706,  0.9843,  0.9843,  0.9843,  0.9843,\n",
      "           0.9843,  0.9843,  0.9843,  0.9843,  0.9843,  0.9843,  0.7490,\n",
      "          -0.5922, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -0.4824,  0.8118,  0.9843,  0.9843,  0.9843,\n",
      "          -0.1529, -0.6863, -0.6863, -0.0980,  0.9137,  0.9843,  0.9843,\n",
      "           0.0510, -0.9765, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -0.5059, -0.1059, -0.1059, -0.1059,\n",
      "          -0.7098, -1.0000, -1.0000, -1.0000,  0.6078,  0.9843,  0.9843,\n",
      "           0.9843, -0.8824, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -0.5529,  0.9843,  0.9843,\n",
      "           0.9843, -0.8824, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -0.6706,  0.9843,  0.9843,\n",
      "           0.9843, -0.8824, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -0.2549,  0.9843,  0.9843,\n",
      "           0.9843, -0.8824, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000,  0.6078,  0.9843,  0.9843,\n",
      "           0.9843, -0.8824, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.5216, -0.2235,\n",
      "          -0.2471, -1.0000, -1.0000, -0.6471,  0.7569,  0.9843,  0.9843,\n",
      "           0.5294, -0.9216, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9137,\n",
      "          -0.8039, -0.1765, -0.3490,  0.4824,  0.4824,  0.7882,  0.9843,\n",
      "           0.9686,  0.4824,  0.4824,  0.7098,  0.9843,  0.9843,  0.6471,\n",
      "          -0.7882, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -0.6706, -0.0902,  0.3569,\n",
      "           0.9843,  0.9843,  0.9843,  0.9843,  0.9843,  0.9843,  0.9843,\n",
      "           0.9843,  0.9843,  0.9843,  0.9843,  0.9843,  0.9843,  0.7333,\n",
      "          -0.0902, -0.9451, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -0.0745,  0.9843,  0.9843,\n",
      "           0.9843,  0.9843,  0.9216,  0.6627,  0.7412,  0.9843,  0.9843,\n",
      "           0.9843,  0.9843,  0.9843,  0.9843,  0.9843,  0.9843,  0.9843,\n",
      "           0.9843,  0.2549, -0.8824, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000,  0.9922,  0.9843,  0.9843,\n",
      "           0.9843,  0.4824, -0.2235, -1.0000, -0.7490,  0.5843,  0.9843,\n",
      "           0.9843,  0.9843,  0.8824, -0.0431, -0.0431,  0.4902,  0.9843,\n",
      "           0.9843,  0.9843,  0.3647, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000,  1.0000,  0.9843,  0.9843,\n",
      "           0.9843,  0.8667,  0.7412,  0.7412,  0.7412,  0.8902,  0.9843,\n",
      "           0.9843,  0.8039, -0.4510, -1.0000, -1.0000, -0.8667,  0.3725,\n",
      "           0.7961,  0.9843,  0.9843, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000,  0.2392,  0.9843,  0.9843,\n",
      "           0.9843,  0.9843,  0.9843,  0.9843,  0.9843,  0.9843,  0.6078,\n",
      "          -0.1686, -0.4902, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -0.5137,  0.9137,  0.2314, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -0.9529, -0.7961,  0.4039,\n",
      "           0.4039,  0.4039,  0.4039,  0.4039, -0.7647, -0.8824, -0.9216,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -0.8902, -0.9529, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000]]]), 'index': np.int64(0)}\n",
      "------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAh8AAADTCAYAAAAh6HE3AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/TGe4hAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAkB0lEQVR4nO3de1hUdf4H8DegDKAwKAqESuIlzbxUJIqYYl5YywtYqRu2qJWWWHnd1ES8RuZaXhYvayZmIkYr4mVX1xCxVtE0zbR0tdAsBBVlQJDrfH9/+Di/xu8xBxjOXHi/nuc8T7w5M+dz9BN+OPOdMw5CCAEiIiIilThaugAiIiKqWzh8EBERkao4fBAREZGqOHwQERGRqjh8EBERkao4fBAREZGqOHwQERGRqjh8EBERkao4fBAREZGqOHzUstGjR6Nly5aWLoOo2i5evAgHBwckJCRYuhQishN1dvhwcHAwaTtw4IClSzVy4MABODg44IsvvrB0KWSFhgwZAjc3NxQWFt53n8jISDg7OyMvL8+sx2ZvUlWo+TO4uLgYc+fONfm52Mu1r56lC7CUTZs2GX396aefYt++fVL+6KOP1ug469atg16vr9FzEJkqMjISO3fuREpKCv7yl79I3y8uLkZqair+9Kc/wcvLywIVEt2h1s9g4E7fz5s3DwAQGhpa4+ejmquzw8eoUaOMvs7MzMS+ffuk/F7FxcVwc3Mz+Tj169evVn1E1TFkyBC4u7sjMTFRcfhITU1FUVERIiMjLVAd0f+r7s9gsg919mUXU4SGhqJjx444fvw4evXqBTc3N8yaNQvAnR/izz33HPz8/KDRaNC6dWssWLAAlZWVRs9x75qPu6+f/+1vf8M//vEPtG7dGhqNBl27dsU333xTrTrnzp0LBwcH/O9//8OoUaOg1WrRtGlTxMTEQAiBy5cvY+jQofDw8ICvry+WLl1q9PiysjLMmTMHgYGB0Gq1aNCgAZ5++mmkp6dLx8rLy8PLL78MDw8PeHp6IioqCt99953imoCzZ8/ihRdeQOPGjeHi4oKnnnoKO3bsqNY5kmlcXV0xbNgwpKWl4erVq9L3ExMT4e7ujiFDhuDGjRuYNm0aOnXqhIYNG8LDwwMDBw7Ed999Z7Z62JtUE3q9HsuWLcNjjz0GFxcX+Pj4YPz48bh586bRfseOHUNYWBiaNGkCV1dXBAQEYOzYsQDu/Mxt2rQpAGDevHmGl3Pmzp1bpVrYy+bF4eMB8vLyMHDgQDz++ONYtmwZ+vTpAwBISEhAw4YNMWXKFCxfvhyBgYGYM2cOZsyYYdLzJiYmYsmSJRg/fjwWLlyIixcvYtiwYSgvL692rSNGjIBer8f777+Pbt26YeHChVi2bBn69++PZs2aYfHixWjTpg2mTZuGgwcPGh5XUFCAjz/+GKGhoVi8eDHmzp2La9euISwsDCdPnjTsp9frMXjwYGzZsgVRUVFYtGgRrly5gqioKKmWM2fOoHv37vjxxx8xY8YMLF26FA0aNEB4eDhSUlKqfY70YJGRkaioqMDnn39ulN+4cQN79+5FREQEXF1d8fPPP2P79u0YNGgQPvzwQ0yfPh3ff/89evfujezsbLPWxN6k6hg/fjymT5+OkJAQLF++HGPGjMHmzZsRFhZm+Fl59epVDBgwABcvXsSMGTOwcuVKREZGIjMzEwDQtGlTrF69GgAQERGBTZs2YdOmTRg2bFi1amIvm4kgIYQQ0dHR4t4/jt69ewsAYs2aNdL+xcXFUjZ+/Hjh5uYmSkpKDFlUVJR4+OGHDV9nZWUJAMLLy0vcuHHDkKempgoAYufOnX9YZ3p6ugAgkpOTDVlsbKwAIMaNG2fIKioqRPPmzYWDg4N4//33DfnNmzeFq6uriIqKMtq3tLTU6Dg3b94UPj4+YuzYsYbsn//8pwAgli1bZsgqKyvFM888IwCIDRs2GPK+ffuKTp06Gf1Z6PV60aNHD9G2bds/PEeqmYqKCvHQQw+J4OBgo3zNmjUCgNi7d68QQoiSkhJRWVlptE9WVpbQaDRi/vz5Rtm9f79K2JtUE/f+DP7qq68EALF582aj/fbs2WOUp6SkCADim2++ue9zX7t2TQAQsbGxJtXCXq59vPLxABqNBmPGjJFyV1dXw38XFhbi+vXrePrpp1FcXIyzZ88+8HlHjBiBRo0aGb5++umnAQA///xztWt99dVXDf/t5OSEp556CkIIvPLKK4bc09MT7dq1MzqOk5MTnJ2dAdyZum/cuIGKigo89dRT+Pbbbw377dmzB/Xr18drr71myBwdHREdHW1Ux40bN7B//34MHz7c8Gdz/fp15OXlISwsDOfPn8dvv/1W7fOkP+bk5ISRI0fi8OHDuHjxoiFPTEyEj48P+vbtC+BObzs63vkRUFlZiby8PDRs2BDt2rUz+ns3B/YmVVVycjK0Wi369+9v+Hu6fv06AgMD0bBhQ8PLFZ6engCAXbt21ejKsanYy+bB4eMBmjVrZmiY3ztz5gwiIiKg1Wrh4eGBpk2bGhZK6XS6Bz6vv7+/0dd3B5F7X8usinufU6vVwsXFBU2aNJHye4+zceNGdO7cGS4uLvDy8kLTpk2xe/duo3O5dOkSHnroIWnBbZs2bYy+vnDhAoQQiImJQdOmTY222NhYAFBcj0Dmc3dBaWJiIgDg119/xVdffYWRI0fCyckJwJ0fgB999BHatm0LjUaDJk2aoGnTpjh16pRJPVwV7E2qqvPnz0On08Hb21v6u7p165bh76l37954/vnnMW/ePDRp0gRDhw7Fhg0bUFpaWit1sZfNo86+28VUv7/CcVd+fj569+4NDw8PzJ8/H61bt4aLiwu+/fZbvPPOOya9tfbuPwD3EkJUu1al5zTlOJ999hlGjx6N8PBwTJ8+Hd7e3nByckJcXBx++umnKtdx9/ynTZuGsLAwxX3u/R+JzCswMBDt27fHli1bMGvWLGzZsgVCCKN3ubz33nuIiYnB2LFjsWDBAjRu3BiOjo6YNGmS2d8ezt6kqtLr9fD29sbmzZsVv393Eend+3FkZmZi586d2Lt3L8aOHYulS5ciMzMTDRs2NGtd7GXz4PBRDQcOHEBeXh62bduGXr16GfKsrCwLVlV9X3zxBVq1aoVt27bBwcHBkN+dnu96+OGHkZ6eLr3d+MKFC0b7tWrVCsCdtxn369evFiunPxIZGYmYmBicOnUKiYmJaNu2Lbp27Wr4/hdffIE+ffpg/fr1Ro/Lz8+XfouzFPZm3dW6dWt8+eWXCAkJUfwl8F7du3dH9+7dsWjRIiQmJiIyMhJJSUl49dVXjXrHUtjLxviySzXcnXJ/P9WWlZVh1apVliqpRpTO58iRIzh8+LDRfndXmK9bt86Q6fV6xMfHG+3n7e2N0NBQrF27FleuXJGOd+3aNXOWT/dx9yrHnDlzcPLkSeneHk5OTtKVtuTkZKt6nZi9WXcNHz4clZWVWLBggfS9iooK5OfnA7jzUvW9ffz4448DgOGll7v/iN99jCWwl43xykc19OjRA40aNUJUVBTeeustODg4YNOmTTV6ycSSBg0ahG3btiEiIgLPPfccsrKysGbNGnTo0AG3bt0y7BceHo6goCBMnToVFy5cQPv27bFjxw7cuHEDAIym+fj4ePTs2ROdOnXCa6+9hlatWiE3NxeHDx/Gr7/+atZ7SZCygIAA9OjRA6mpqQAgDR+DBg3C/PnzMWbMGPTo0QPff/89Nm/ebPiNyhqwN+uu3r17Y/z48YiLi8PJkycxYMAA1K9fH+fPn0dycjKWL1+OF154ARs3bsSqVasQERGB1q1bo7CwEOvWrYOHhweeffZZAHdePu/QoQO2bt2KRx55BI0bN0bHjh3RsWNH1c6HvWyMw0c1eHl5YdeuXZg6dSpmz56NRo0aYdSoUejbt+99X3uzZqNHj0ZOTg7Wrl2LvXv3okOHDvjss8+QnJxs9FkITk5O2L17N95++21s3LgRjo6OiIiIQGxsLEJCQuDi4mLYt0OHDjh27BjmzZuHhIQE5OXlwdvbG0888QTmzJljgbOsmyIjI3Ho0CEEBQVJr//OmjULRUVFSExMxNatW/Hkk09i9+7dJt+rRg3szbptzZo1CAwMxNq1azFr1izUq1cPLVu2xKhRoxASEgLgzpBy9OhRJCUlITc3F1qtFkFBQdi8eTMCAgIMz/Xxxx/jzTffxOTJk1FWVobY2FhVhw/2sjEHYau/rpPV2L59OyIiIvD1118bfiAQWQP2JtkLe+tlDh9UJbdv3zZa/FVZWYkBAwbg2LFjyMnJMWlhGFFtYG+SvagLvcyXXahK3nzzTdy+fRvBwcEoLS3Ftm3bcOjQIbz33nt28T8E2S72JtmLutDLvPJBVZKYmIilS5fiwoULKCkpQZs2bfDGG29g4sSJli6N6jj2JtmLutDLHD6IiIhIVbzPBxEREamq1tZ8xMfHY8mSJcjJyUGXLl2wcuVKBAUFPfBxer0e2dnZcHd3t4q70pFtEkKgsLAQfn5+hg9PMxV7lyyJvUu2qkq9WxsflZuUlCScnZ3FJ598Is6cOSNee+014enpKXJzcx/42MuXLwsA3LiZZbt8+TJ7l5tNbuxdbra6mdK7tTJ8BAUFiejoaMPXlZWVws/PT8TFxT3wsfn5+Rb/g+NmP1t+fj57l5tNbuxdbra6mdK7Zl/zUVZWhuPHjxt90I2joyP69esn3cMeuHPv/YKCAsNWWFho7pKoDqvKJWT2LlkT9i7ZKlN61+zDx/Xr11FZWQkfHx+j3MfHBzk5OdL+cXFx0Gq1hq1FixbmLonIJOxdslXsXbI1Fn+3y8yZM6HT6Qzb5cuXLV0SkUnYu2Sr2LtkaWZ/t0uTJk3g5OSE3Nxcozw3Nxe+vr7S/hqNBhqNxtxlEFUZe5dsFXuXbI3Zr3w4OzsjMDAQaWlphkyv1yMtLQ3BwcHmPhyR2bB3yVaxd8nmVGk5tYmSkpKERqMRCQkJ4ocffhDjxo0Tnp6eIicn54GP1el0Fl+py81+Np1Ox97lZpMbe5ebrW6m9G6tDB9CCLFy5Urh7+8vnJ2dRVBQkMjMzDTpcfyfgJs5t6r+AGfvcrOWjb3LzVY3U3rX6j7bpaCgAFqt1tJlkJ3Q6XTw8PBQ5VjsXTIn9i7ZKlN61+LvdiEiIqK6hcMHERERqYrDBxEREamKwwcRERGpisMHERERqYrDBxEREamKwwcRERGpisMHERERqYrDBxEREamKwwcRERGpisMHERERqaqepQsgIvvl5OQkZSEhIVL27rvvStmAAQMUnzM7O1vKunXrJmW//vqrKSWSnXJzc5MyjUZj9uOEhoZK2dixY01+/KRJk6Tsp59+qkFFtoFXPoiIiEhVHD6IiIhIVRw+iIiISFUcPoiIiEhVXHBqR1xcXKQsLCxMcd8hQ4ZI2ZgxY6QsKSlJyl566aVqVEd10eeffy5l4eHhJj1Wr9cr5r6+vlLWtWtXKeOC07pt3rx5UjZlyhQLVPLHYmJiLF2CRfDKBxEREamKwwcRERGpisMHERERqYrDBxEREamKC05t1LRp06Rs+PDhUhYYGGjycwohpGzEiBFSNmfOHCm7cOGCycch2+boqPw7y+zZs6VMaWHz7t27pWzRokVSVlFRoXico0ePStlzzz0nZSkpKYqPJ/vTs2dPKRs5cqQFKqm6DRs2SFlxcbGUvfHGG1J26tSpWqlJDbzyQURERKri8EFERESq4vBBREREquLwQURERKriglMbMHnyZCl77733pKxePfmvU2kR6f2Ul5dLWWlpqZR5enqa/Jxkf5555hnFPDY2VsrWr18vZePGjTPpOO7u7oo5FzfTvdauXStlfn5+Fqik6jp37mzSfqmpqVL24osvKu577NixGtWkBl75ICIiIlVx+CAiIiJVcfggIiIiVXH4ICIiIlVx+CAiIiJV8d0uVqZ9+/ZSpvRuFycnJykrKiqSMqVbXgPAb7/9JmXXrl0zaT++26DucHV1lbKNGzcq7pueni5lEydONOuxAaBNmzZS9tVXX1X7OGT7lPosMTFRyry9vWt0nLffflvKvvzyS5Mfr/QxAHPnzpUyNzc3KfP395eyYcOGKR7nxIkTUlZZWWlCherhlQ8iIiJSFYcPIiIiUhWHDyIiIlIVhw8iIiJSFRecWpkFCxZIWbNmzaTs9OnTUqa0+Oinn34yT2FUJzk6yr+f+Pr6Ku578OBBKSsrKzN7TUqUPlqgQYMGUqbX66Xs9u3btVITqUdpsfPIkSOl7Mknn6zRcfbs2SNlVVmAf/bsWSl76aWXpOzxxx836fneeecdxXzx4sVSptPpTHpOtfDKBxEREamKwwcRERGpisMHERERqYrDBxEREamqygtODx48iCVLluD48eO4cuUKUlJSEB4ebvi+EAKxsbFYt24d8vPzERISgtWrV6Nt27bmrNtu9e7dW8qOHj0qZUp3yrtx44bZ60lKSjJpP6XFXdaGvVt1Sgs0a6PPaurll182KVNamNivX79aqcmc2LtVl5GRYVJmadHR0VL23//+1wKVqKvKVz6KiorQpUsXxMfHK37/gw8+wIoVK7BmzRocOXIEDRo0QFhYGEpKSmpcLFFNsHfJVrF3yd5U+crHwIEDMXDgQMXvCSGwbNkyzJ49G0OHDgUAfPrpp/Dx8cH27dsVfzsuLS1FaWmp4euCgoKqlkRkEvYu2Sr2Ltkbs675yMrKQk5OjtFlTK1Wi27duuHw4cOKj4mLi4NWqzVsLVq0MGdJRCZh75KtYu+SLTLr8JGTkwMA8PHxMcp9fHwM37vXzJkzodPpDNvly5fNWRKRSdi7ZKvYu2SLLH6HU41GA41GY+kyVNenTx/FXOnPYvLkyVJW00V/Li4uUvb3v/9dytq3by9ly5cvr9Gx7UVd6F2lu3/u2LFDcd9BgwZJmaenp5Tl5+ebdOyaLpYsLi6WshUrVtToOe1FXehdW1FXX/Iy65WPu7ddzs3NNcpzc3Pve0tmImvA3iVbxd4lW2TW4SMgIAC+vr5IS0szZAUFBThy5AiCg4PNeSgis2Lvkq1i75ItqvLLLrdu3TL6IJ2srCycPHkSjRs3hr+/PyZNmoSFCxeibdu2CAgIQExMDPz8/Izek05kCexdslXsXbI3VR4+jh07ZrReYcqUKQCAqKgoJCQk4K9//SuKioowbtw45Ofno2fPntizZ4/iGgMiNbF3yVaxd8neVHn4CA0NhRDivt93cHDA/PnzMX/+/BoVRmRu7F2yVexdsjcWf7dLXTV9+nTFXOndBT/++KOUeXt7m3ScVq1aKeZbt26VMqV3JkyYMEHKNm/ebNKxyT4dO3ZMMR89erSU1a9f36TndHZ2lrKYmBiTayorK5Oy4cOHS9m///1vk5+TSA1du3a1dAkWwQ+WIyIiIlVx+CAiIiJVcfggIiIiVXH4ICIiIlVxwakKGjRoIGX3u/Og0sK77du3S1mvXr2kzNFRniX1er3icRYvXixln3zyiZT9/t4CRADu+2FlSkaNGiVlH330kZS99dZbUta/f3+Tj6O02JWLS8kWKPV+XcArH0RERKQqDh9ERESkKg4fREREpCoOH0RERKQqLjhVQUVFhZSVl5cr7qvVaqVMaXGpkoyMDClLSkpS3Pezzz6Tslu3bpl0HKrbzp8/r5gnJydLmdLC5hEjRkhZhw4dpKy0tFTxOCtWrJCynTt3Ku5LZIqePXtKWbt27aSssrJSyhISEkw+TseOHaXMy8vL5Mff69ChQ4r5/f59sSa88kFERESq4vBBREREquLwQURERKri8EFERESq4oJTFbRp00bKavoxygsXLpSyOXPm1Og5iUxRVFSkmKekpEjZiy++KGWm9v6lS5cU8xkzZpj0eLIdSneB9vDwUNw3PDxcyq5evSplEyZMMPn4jzzyiJT5+flJmdIdo19++WWTj9OiRQuTMiVnzpyRspEjRyruW1xcbHJNlsIrH0RERKQqDh9ERESkKg4fREREpCoOH0RERKQqLjg1M6XFpVOnTpUyIYTJz6l0N1KlO0cSqaFly5aKubk/GnzRokVmfT5Sn9Kda5999lkpCw4OljKlhaWW5ugo/74eGhqqyrGVFuX++c9/Vtx35cqVUna/OwZbCq98EBERkao4fBAREZGqOHwQERGRqjh8EBERkao4fBAREZGq+G4XM1Naoa10+92ZM2cqPv6VV16RshEjRkjZvn37pEzpXTFENdG5c2cpmzt3ruK+3bt3r/Zx/vWvf0lZQkJCtZ+PrMOgQYOkLC4uzuzHKSkpkbKff/5ZypTeMQIADz/8sNlrMjeld5nd712PHTt2lLK3335bynQ6XY3rqi5e+SAiIiJVcfggIiIiVXH4ICIiIlVx+CAiIiJVOYiq3OdbBQUFBdBqtZYuo9q+//57KcvOzpaysLAwxcd7enpK2dmzZ6Xs0KFDUjZs2DATKqxbdDodPDw8VDmWrfeu0iK1jIwMKVPqUQC4fv26lK1evVrKBg8eLGWnT5+WsqioKMXj1BX20Lt6vV7KavpPzoEDB6QsMTFRytavXy9l9/togM8//1zKAgMDq1zbXYWFhYq5qR+L0b9/fynr3bt3tesBgNTUVCmrrX8zTOldXvkgIiIiVXH4ICIiIlVx+CAiIiJVcfggIiIiVfEOpyrYsWOHyfvm5+dL2apVq6QsNja2JiURSZTugKi0uDQrK0vx8d26dZOyvLw8KWvVqpWU+fr6Slm9eso/nioqKhRzsj4ODg5SVtMFp0888YSUBQQESNm7775r8nN6eXlVu57c3FwpGz16tOK+//nPf0x6zjVr1kjZJ598ImVBQUGKj1f6/2no0KEmHVstvPJBREREquLwQURERKri8EFERESq4vBBREREqqrSgtO4uDhs27YNZ8+ehaurK3r06IHFixejXbt2hn1KSkowdepUJCUlobS0FGFhYVi1ahV8fHzMXryl9enTR8oee+wxKduyZUuNjjN//nwpGzFihJQlJSVJ2ciRI2t0bHvB3n0wpYWgSu63EFRpIeCXX34pZUr/P+zatUvKunfvrnicr7/++kEl2hVb7t0NGzZIWU3vXKt0J9bauDvryZMnpezjjz+WMqU7UKenp9fo2Ddv3pSyiIgIKevVq5fi43fv3i1lSndxtaQqXfnIyMhAdHQ0MjMzsW/fPpSXl2PAgAEoKioy7DN58mTs3LkTycnJyMjIQHZ2Nm/7TRbH3iVbxd4le1SlKx979uwx+johIQHe3t44fvw4evXqBZ1Oh/Xr1yMxMRHPPPMMgDuT76OPPorMzEzF32RKS0tRWlpq+LqgoKA650H0h9i7ZKvYu2SParTmQ6fTAQAaN24MADh+/DjKy8vRr18/wz7t27eHv78/Dh8+rPgccXFx0Gq1hq1FixY1KYnIJOxdslXsXbIH1R4+9Ho9Jk2ahJCQEMOnYebk5MDZ2Vm6MZGPjw9ycnIUn2fmzJnQ6XSG7fLly9Uticgk7F2yVexdshfVvsNpdHQ0Tp8+XePFXxqNBhqNpkbPYSlXr16VMqXLl0p32ps6dWqNjr1t2zYpCw8Pr9Fz1hXsXWVK/1ApLXy732/J9748AADFxcVSdunSJZPqCQ0NVczr2oLT37O13n399delbPbs2VK2du3aWq8FuPPnp+Tu1aTfKy8vlzKlfrakgwcPKubNmjWTspKSktoup0qqdeVj4sSJ2LVrF9LT09G8eXND7uvri7KyMukW4bm5uYq3eyVSG3uXbBV7l+xJlYYPIQQmTpyIlJQU7N+/X7qffmBgIOrXr4+0tDRDdu7cOfzyyy8IDg42T8VE1cDeJVvF3iV7VKWXXaKjo5GYmIjU1FS4u7sbLtNqtVq4urpCq9XilVdewZQpU9C4cWN4eHjgzTffRHBw8H3fs0+kBvYu2Sr2LtmjKg0fq1evBiC/FrthwwbDp/h99NFHcHR0xPPPP290sxsiS2Lvkq1i75I9qtLwYcpHIbu4uCA+Ph7x8fHVLorI3Ni7ZKvYu2SPqv1uFwLOnDkjZSkpKVL21ltvSZnSO2UAYP369VKmtOr61q1bUubl5SVlSqueAeC3335TzKnuioyMlLI2bdpI2YQJExQfr/RxA507d5ayDh06VKM6skVlZWVSlp2dLWWDBw9Wo5w6wxZuGscPliMiIiJVcfggIiIiVXH4ICIiIlVx+CAiIiJVOQhTllKrqKCgAFqt1tJlVJvSLc5XrlwpZX5+foqP//0nTd51/fp1KVNaSPrDDz9IWadOnRSPU1fodDp4eHiocixb792acnd3lzKljxYYMmSIlJ06dUrKJk+erHicK1euVKM628PeJVtlSu/yygcRERGpisMHERERqYrDBxEREamKwwcRERGpigtOVfDYY49J2euvv664r6urq5SNGTNGypKSkqQsOTlZyrZv325ChfaLi/bIVrF3yVZxwSkRERFZHQ4fREREpCoOH0RERKQqDh9ERESkKi44JbvGRXtkq9i7ZKu44JSIiIisDocPIiIiUhWHDyIiIlIVhw8iIiJSFYcPIiIiUhWHDyIiIlIVhw8iIiJSFYcPIiIiUhWHDyIiIlIVhw8iIiJSFYcPIiIiUhWHDyIiIlIVhw8iIiJSFYcPIiIiUpXVDR9CCEuXQHZEzX5i75I5sXfJVpnST1Y3fBQWFlq6BLIjavYTe5fMib1LtsqUfnIQVjby6vV6ZGdnw93dHYWFhWjRogUuX74MDw8PS5dWYwUFBTwflQghUFhYCD8/Pzg6qjNjs3dthzWfD3vXvKz577o6rPl8qtK79VSqyWSOjo5o3rw5AMDBwQEA4OHhYXV/yDXB81GHVqtV9XjsXdtjrefD3jU/no86TO1dq3vZhYiIiOwbhw8iIiJSlVUPHxqNBrGxsdBoNJYuxSx4PnWHvf3Z8HzqDnv7s+H5WCerW3BKRERE9s2qr3wQERGR/eHwQURERKri8EFERESq4vBBREREquLwQURERKqy2uEjPj4eLVu2hIuLC7p164ajR49auiSTHTx4EIMHD4afnx8cHBywfft2o+8LITBnzhw89NBDcHV1Rb9+/XD+/HnLFPsAcXFx6Nq1K9zd3eHt7Y3w8HCcO3fOaJ+SkhJER0fDy8sLDRs2xPPPP4/c3FwLVWwdbLV/2bvsXfaudbD3/rXK4WPr1q2YMmUKYmNj8e2336JLly4ICwvD1atXLV2aSYqKitClSxfEx8crfv+DDz7AihUrsGbNGhw5cgQNGjRAWFgYSkpKVK70wTIyMhAdHY3MzEzs27cP5eXlGDBgAIqKigz7TJ48GTt37kRycjIyMjKQnZ2NYcOGWbBqy7Ll/mXvsnfZu9bB7vtXWKGgoCARHR1t+LqyslL4+fmJuLg4C1ZVPQBESkqK4Wu9Xi98fX3FkiVLDFl+fr7QaDRiy5YtFqiwaq5evSoAiIyMDCHEndrr168vkpOTDfv8+OOPAoA4fPiwpcq0KHvpX/Zu3cPetV721r9Wd+WjrKwMx48fR79+/QyZo6Mj+vXrh8OHD1uwMvPIyspCTk6O0flptVp069bNJs5Pp9MBABo3bgwAOH78OMrLy43Op3379vD397eJ8zE3e+5f9q59Y+9aN3vrX6sbPq5fv47Kykr4+PgY5T4+PsjJybFQVeZz9xxs8fz0ej0mTZqEkJAQdOzYEcCd83F2doanp6fRvrZwPrXBnvuXvWvf2LvWyx77t56lCyDbER0djdOnT+Prr7+2dClEVcLeJVtmj/1rdVc+mjRpAicnJ2nFbm5uLnx9fS1UlfncPQdbO7+JEydi165dSE9PR/PmzQ25r68vysrKkJ+fb7S/tZ9PbbHn/mXv2jf2rnWy1/61uuHD2dkZgYGBSEtLM2R6vR5paWkIDg62YGXmERAQAF9fX6PzKygowJEjR6zy/IQQmDhxIlJSUrB//34EBAQYfT8wMBD169c3Op9z587hl19+scrzqW323L/sXfvG3rUudt+/Fl7wqigpKUloNBqRkJAgfvjhBzFu3Djh6ekpcnJyLF2aSQoLC8WJEyfEiRMnBADx4YcfihMnTohLly4JIYR4//33haenp0hNTRWnTp0SQ4cOFQEBAeL27dsWrlz2xhtvCK1WKw4cOCCuXLli2IqLiw37vP7668Lf31/s379fHDt2TAQHB4vg4GALVm1Ztty/7F32LnvXOth7/1rl8CGEECtXrhT+/v7C2dlZBAUFiczMTEuXZLL09HQBQNqioqKEEHfe9hUTEyN8fHyERqMRffv2FefOnbNs0fehdB4AxIYNGwz73L59W0yYMEE0atRIuLm5iYiICHHlyhXLFW0FbLV/2bvsXfaudbD3/nUQQojavbZCRERE9P+sbs0HERER2TcOH0RERKQqDh9ERESkKg4fREREpCoOH0RERKQqDh9ERESkKg4fREREpCoOH0RERKQqDh9ERESkKg4fREREpCoOH0RERKSq/wMMc4rF/5VZLAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "f, axarr = plt.subplots(1, 3)\n",
    "\n",
    "train_dataset = MNISTTrainDataset(train_df.iloc[:, 1:].values.astype(np.uint8), train_df.iloc[:, 0].values, train_df.index.values)\n",
    "print(len(train_dataset))\n",
    "print(train_dataset[0])\n",
    "axarr[0].imshow(train_dataset[0][\"image\"].squeeze(), cmap=\"gray\")\n",
    "axarr[0].set_title(\"Train Image\")\n",
    "print(\"-\"*30)\n",
    "\n",
    "val_dataset = MNISTValDataset(val_df.iloc[:, 1:].values.astype(np.uint8), val_df.iloc[:, 0].values, val_df.index.values)\n",
    "print(len(val_dataset))\n",
    "print(val_dataset[0])\n",
    "axarr[1].imshow(val_dataset[0][\"image\"].squeeze(), cmap=\"gray\")\n",
    "axarr[1].set_title(\"Val Image\")\n",
    "print(\"-\"*30)\n",
    "\n",
    "test_dataset = MNISTSubmitDataset(test_df.values.astype(np.uint8), test_df.index.values)\n",
    "print(len(test_dataset))\n",
    "print(test_dataset[0])\n",
    "axarr[2].imshow(test_dataset[0][\"image\"].squeeze(), cmap=\"gray\")\n",
    "axarr[2].set_title(\"Test Image\")\n",
    "print(\"-\"*30)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-26T14:44:42.888796Z",
     "iopub.status.busy": "2023-09-26T14:44:42.888379Z",
     "iopub.status.idle": "2023-09-26T14:44:42.896871Z",
     "shell.execute_reply": "2023-09-26T14:44:42.895799Z",
     "shell.execute_reply.started": "2023-09-26T14:44:42.888762Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(dataset=train_dataset,\n",
    "                              batch_size=BATCH_SIZE,\n",
    "                              shuffle=True)\n",
    "\n",
    "val_dataloader = DataLoader(dataset=val_dataset,\n",
    "                            batch_size=BATCH_SIZE,\n",
    "                            shuffle=True)\n",
    "\n",
    "test_dataloader = DataLoader(dataset=test_dataset,\n",
    "                             batch_size=BATCH_SIZE,\n",
    "                             shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-26T14:44:51.881470Z",
     "iopub.status.busy": "2023-09-26T14:44:51.880896Z",
     "iopub.status.idle": "2023-09-26T14:56:27.518896Z",
     "shell.execute_reply": "2023-09-26T14:56:27.517839Z",
     "shell.execute_reply.started": "2023-09-26T14:44:51.881427Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 74/74 [05:22<00:00,  4.35s/it]\n",
      "100%|██████████| 9/9 [00:08<00:00,  1.05it/s]\n",
      "  2%|▎         | 1/40 [05:30<3:35:04, 330.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Train Loss EPOCH 1: 2.2376\n",
      "Valid Loss EPOCH 1: 1.9256\n",
      "Train Accuracy EPOCH 1: 0.1622\n",
      "Valid Accuracy EPOCH 1: 0.3269\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 3/74 [00:21<08:27,  7.14s/it]\n",
      "  2%|▎         | 1/40 [05:52<3:49:02, 352.37s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 22\u001b[0m\n\u001b[1;32m     19\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(y_pred, label)\n\u001b[1;32m     21\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 22\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     25\u001b[0m train_running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/ml-platform/vit-exp/vit-exp/lib/python3.11/site-packages/torch/_tensor.py:525\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    517\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    518\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    523\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    524\u001b[0m     )\n\u001b[0;32m--> 525\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ml-platform/vit-exp/vit-exp/lib/python3.11/site-packages/torch/autograd/__init__.py:267\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    262\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 267\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ml-platform/vit-exp/vit-exp/lib/python3.11/site-packages/torch/autograd/graph.py:744\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    743\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 744\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    745\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    746\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    748\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), betas=ADAM_BETAS, lr=LEARNING_RATE, weight_decay=ADAM_WEIGHT_DECAY)\n",
    "\n",
    "start = timeit.default_timer()\n",
    "for epoch in tqdm(range(EPOCHS), position=0, leave=True):\n",
    "    model.train()\n",
    "    train_labels = []\n",
    "    train_preds = []\n",
    "    train_running_loss = 0\n",
    "    for idx, img_label in enumerate(tqdm(train_dataloader, position=0, leave=True)):\n",
    "        img = img_label[\"image\"].float().to(device)\n",
    "        label = img_label[\"label\"].type(torch.uint8).to(device)\n",
    "        y_pred = model(img)\n",
    "        y_pred_label = torch.argmax(y_pred, dim=1)\n",
    "\n",
    "        train_labels.extend(label.cpu().detach())\n",
    "        train_preds.extend(y_pred_label.cpu().detach())\n",
    "        \n",
    "        loss = criterion(y_pred, label)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_running_loss += loss.item()\n",
    "    train_loss = train_running_loss / (idx + 1)\n",
    "\n",
    "    model.eval()\n",
    "    val_labels = []\n",
    "    val_preds = []\n",
    "    val_running_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for idx, img_label in enumerate(tqdm(val_dataloader, position=0, leave=True)):\n",
    "            img = img_label[\"image\"].float().to(device)\n",
    "            label = img_label[\"label\"].type(torch.uint8).to(device)         \n",
    "            y_pred = model(img)\n",
    "            y_pred_label = torch.argmax(y_pred, dim=1)\n",
    "            \n",
    "            val_labels.extend(label.cpu().detach())\n",
    "            val_preds.extend(y_pred_label.cpu().detach())\n",
    "            \n",
    "            loss = criterion(y_pred, label)\n",
    "            val_running_loss += loss.item()\n",
    "    val_loss = val_running_loss / (idx + 1)\n",
    "\n",
    "    print(\"-\"*30)\n",
    "    print(f\"Train Loss EPOCH {epoch+1}: {train_loss:.4f}\")\n",
    "    print(f\"Valid Loss EPOCH {epoch+1}: {val_loss:.4f}\")\n",
    "    print(f\"Train Accuracy EPOCH {epoch+1}: {sum(1 for x,y in zip(train_preds, train_labels) if x == y) / len(train_labels):.4f}\")\n",
    "    print(f\"Valid Accuracy EPOCH {epoch+1}: {sum(1 for x,y in zip(val_preds, val_labels) if x == y) / len(val_labels):.4f}\")\n",
    "    print(\"-\"*30)\n",
    "\n",
    "stop = timeit.default_timer()\n",
    "print(f\"Training Time: {stop-start:.2f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-26T14:56:27.521475Z",
     "iopub.status.busy": "2023-09-26T14:56:27.520895Z",
     "iopub.status.idle": "2023-09-26T14:56:27.577032Z",
     "shell.execute_reply": "2023-09-26T14:56:27.576023Z",
     "shell.execute_reply.started": "2023-09-26T14:56:27.521442Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-26T15:27:53.531252Z",
     "iopub.status.busy": "2023-09-26T15:27:53.530890Z",
     "iopub.status.idle": "2023-09-26T15:27:58.155874Z",
     "shell.execute_reply": "2023-09-26T15:27:58.154902Z",
     "shell.execute_reply.started": "2023-09-26T15:27:53.531223Z"
    }
   },
   "outputs": [],
   "source": [
    "labels = []\n",
    "ids = []\n",
    "imgs = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for idx, sample in enumerate(tqdm(test_dataloader, position=0, leave=True)):\n",
    "        img = sample[\"image\"].to(device)\n",
    "        ids.extend([int(i)+1 for i in sample[\"index\"]])\n",
    "        \n",
    "        outputs = model(img)\n",
    "        \n",
    "        imgs.extend(img.detach().cpu())\n",
    "        labels.extend([int(i) for i in torch.argmax(outputs, dim=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-26T15:42:29.857582Z",
     "iopub.status.busy": "2023-09-26T15:42:29.856995Z",
     "iopub.status.idle": "2023-09-26T15:42:31.213526Z",
     "shell.execute_reply": "2023-09-26T15:42:31.212512Z",
     "shell.execute_reply.started": "2023-09-26T15:42:29.857521Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "f, axarr = plt.subplots(2, 3)\n",
    "counter = 0\n",
    "for i in range(2):\n",
    "    for j in range(3):\n",
    "        axarr[i][j].imshow(imgs[counter].squeeze(), cmap=\"gray\")\n",
    "        axarr[i][j].set_title(f\"Predicted {labels[counter]}\")\n",
    "        counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-26T15:26:49.300600Z",
     "iopub.status.busy": "2023-09-26T15:26:49.300211Z",
     "iopub.status.idle": "2023-09-26T15:26:49.399094Z",
     "shell.execute_reply": "2023-09-26T15:26:49.397973Z",
     "shell.execute_reply.started": "2023-09-26T15:26:49.300546Z"
    }
   },
   "outputs": [],
   "source": [
    "submission_df = pd.DataFrame(list(zip(ids, labels)),\n",
    "               columns =[\"ImageId\", \"Label\"])\n",
    "submission_df.to_csv(\"submission.csv\", index=False)\n",
    "submission_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
